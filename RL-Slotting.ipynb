{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os, sys, time, datetime, json, random\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD , Adam, RMSprop\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "# 10x10 storage spaces, with value indicating % space free (initially 1.0 ie. all are empty)\n",
    "warehouse_layout = [\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]\n",
    "]\n",
    "\n",
    "# ACTIONS\n",
    "# agent can assign a SKU to a gicen block or remove a SKU from a given block\n",
    "actions = {1: 'assign_sku', 2: 'remove_sku'}\n",
    "num_actions = len(actions)\n",
    "\n",
    "#EXPLORATION FACTOR\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACTIONS(object):\n",
    "    \n",
    "    def __init__(self, action_id, item_id, quantity, block_row, block_col, status):\n",
    "        self.action_id = action_id\n",
    "        self.item_id = item_id\n",
    "        self.quantity = quantity\n",
    "        self.block_row = block_row\n",
    "        self.block_col = block_col\n",
    "        self.status = status\n",
    "\n",
    "\n",
    "class WAREHOUSE_BLOCKS(object):\n",
    "    \n",
    "    def __init__(self, warehouse_layout, item_log):\n",
    "        self.warehouse_layout = np.array(warehouse_layout)\n",
    "        nrows, ncols = self.warehouse_layout.shape\n",
    "        for row in range(nrows):\n",
    "            for col in range(ncols):\n",
    "                self.warehouse_layout[row, col] = 1.0\n",
    "        self.action_log = []\n",
    "        self.total_reward = -math.inf\n",
    "        self.block_capacity = 100.0\n",
    "        self.item_log = item_log\n",
    "        self.item_iterator = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        nrows, ncols = self.warehouse_layout.shape\n",
    "        for row in range(nrows):\n",
    "            for col in range(ncols):\n",
    "                self.warehouse_layout[row, col] = 0.0\n",
    "        self.action_log = []\n",
    "        self.total_reward = -math.inf\n",
    "        self.item_iterator = 0\n",
    "        \n",
    "    def update(self, action):\n",
    "        target_row = action.block_row\n",
    "        target_col = action.block_col\n",
    "        # determine if action is valid\n",
    "        if (action.action_id == 1):\n",
    "            if (self.warehouse_layout[target_row, target_col] == 0.0):\n",
    "                action.status = 0\n",
    "            if (action.quantity > self.warehouse_layout[target_row, target_col] * self.block_capacity):\n",
    "                action.status = 0\n",
    "        elif (action.action_id == 2):\n",
    "            if (self.warehouse_layout[target_row, target_col] == 0.0):\n",
    "                action.status = 0\n",
    "            if (action.quantity > (1.0 - self.warehouse_layout[target_row, target_col]) * self.block_capacity):\n",
    "                action.status = 0\n",
    "        # perform action if action is valid\n",
    "        if (action.status):\n",
    "            self.warehouse_layout[target_row, target_col] = self.warehouse_layout[target_row, target_col] - action.quantity / self.block_capacity\n",
    "            self.action_log.append(action)\n",
    "            \n",
    "    def get_reward(self, warehouse_log):\n",
    "        if not self.action_log[-1].status:\n",
    "            return 0\n",
    "        reward = 0.0\n",
    "        latest_action = self.action_log[-1]\n",
    "        item = latest_action.item_id\n",
    "        ideal_zone = warehouse_log[item]\n",
    "        given_zone = -1\n",
    "        if latest_action.block_row in [0, 1, 2]:\n",
    "            given_zone = 1\n",
    "        elif latest_action.block_row in [3, 4, 5]:\n",
    "            given_zone = 2\n",
    "        elif latest_action.block_row in [6, 7, 8, 9]:\n",
    "            given_zone = 3\n",
    "        # reward based on frequency zone\n",
    "        if given_zone == ideal_zone:\n",
    "            reward += 0.5\n",
    "        else:\n",
    "            reward += -(abs(ideal_zone - given_zone) / 2)\n",
    "        # print(reward)\n",
    "        # reward based on empty space\n",
    "        reward += -(abs(self.warehouse_layout[latest_action.block_row, latest_action.block_col]))\n",
    "        # print(reward)\n",
    "        return reward\n",
    "    \n",
    "    def act(self, action, warehouse_log):\n",
    "        action.item_id = self.item_log[self.item_iterator][0]\n",
    "        action.quantity = self.item_log[self.item_iterator][1]\n",
    "        self.update(action)\n",
    "        if action.status:\n",
    "            self.total_reward += self.get_reward(warehouse_log)\n",
    "            self.item_iterator = self.item_iterator + 1\n",
    "            \n",
    "    def observe(self):\n",
    "        return np.array(self.warehouse_layout).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class warehouse_state(object):\n",
    "    \n",
    "    def __init__(self, warehouse_layout, item_log):\n",
    "        self.warehouse_layout = np.array(warehouse_layout)\n",
    "        nrows, ncols = self.warehouse_layout.shape\n",
    "        for row in range(nrows):\n",
    "            for col in range(ncols):\n",
    "                self.warehouse_layout[row, col] = 1.0\n",
    "        self.action_log = []\n",
    "        self.total_reward = -math.inf\n",
    "        self.block_capacity = 100.0\n",
    "        self.item_log = item_log\n",
    "        self.item_iterator = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        nrows, ncols = self.warehouse_layout.shape\n",
    "        for row in range(nrows):\n",
    "            for col in range(ncols):\n",
    "                self.warehouse_layout[row, col] = 1.0\n",
    "        self.action_log = []\n",
    "        self.total_reward = -math.inf\n",
    "        self.item_iterator = 0\n",
    "        \n",
    "    def update(self, action):\n",
    "        target_row = action.block_row\n",
    "        target_col = action.block_col\n",
    "        # determine if action is valid\n",
    "        if (action.action_id == 1):\n",
    "            if (self.warehouse_layout[target_row, target_col] == 0.0):\n",
    "                action.status = 0\n",
    "            if (action.quantity > self.warehouse_layout[target_row, target_col] * self.block_capacity):\n",
    "                action.status = 0\n",
    "        elif (action.action_id == 2):\n",
    "            if (self.warehouse_layout[target_row, target_col] == 0.0):\n",
    "                action.status = 0\n",
    "            if (action.quantity > (1.0 - self.warehouse_layout[target_row, target_col]) * self.block_capacity):\n",
    "                action.status = 0\n",
    "        # perform action if action is valid\n",
    "        if (action.status):\n",
    "            self.warehouse_layout[target_row, target_col] = self.warehouse_layout[target_row, target_col] - action.quantity / self.block_capacity\n",
    "            self.action_log.append(action)\n",
    "            \n",
    "    def get_reward(self, warehouse_log):\n",
    "        if not self.action_log[-1].status:\n",
    "            return 0\n",
    "        reward = 0.0\n",
    "        latest_action = self.action_log[-1]\n",
    "        item = latest_action.item_id\n",
    "        ideal_zone = warehouse_log[item]\n",
    "        given_zone = -1\n",
    "        if latest_action.block_row in [0, 1, 2]:\n",
    "            given_zone = 1\n",
    "        elif latest_action.block_row in [3, 4, 5]:\n",
    "            given_zone = 2\n",
    "        elif latest_action.block_row in [6, 7, 8, 9]:\n",
    "            given_zone = 3\n",
    "        # reward based on frequency zone\n",
    "        if given_zone == ideal_zone:\n",
    "            reward += 0.5\n",
    "        else:\n",
    "            reward += -(abs(ideal_zone - given_zone) / 2)\n",
    "        # print(reward)\n",
    "        # reward based on empty space\n",
    "        reward += -(abs(self.warehouse_layout[latest_action.block_row, latest_action.block_col]))\n",
    "        # print(reward)\n",
    "        return reward\n",
    "    \n",
    "    def act(self, action, warehouse_log):\n",
    "        action.item_id = self.item_log[self.item_iterator][0]\n",
    "        action.quantity = self.item_log[self.item_iterator][1]\n",
    "        self.update(action)\n",
    "        if action.status:\n",
    "            self.total_reward += self.get_reward(warehouse_log)\n",
    "            self.item_iterator = self.item_iterator + 1\n",
    "            \n",
    "    def observe(self):\n",
    "        return np.array(self.warehouse_layout).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'item_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d484ab9b2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwarehouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWAREHOUSE_BLOCKS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarehouse_layout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwarehouse_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;36m1256\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mitem_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2157\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcurr_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACTIONS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwarehouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarehouse_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'item_log'"
     ]
    }
   ],
   "source": [
    "warehouse = WAREHOUSE_BLOCKS(warehouse_layout)\n",
    "warehouse_log = { 1256: 3 }\n",
    "item_log = [[1256, 90], [2157, 75]]\n",
    "curr_action = ACTIONS(1, 1256, 90, 2, 3, 1)\n",
    "warehouse.act(curr_action, warehouse_log)\n",
    "print(warehouse.total_reward)\n",
    "print(warehouse.warehouse_layout)\n",
    "print(warehouse.observe().shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def simulate_slotting(model, warehouse, item_log, warehouse_log):\n",
    "    warehouse.reset()\n",
    "    item_index = 0\n",
    "    while True:\n",
    "        # get next action\n",
    "        # act\n",
    "        # check if all items placed or no place available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "class EXPERIENCE(object):\n",
    "    \n",
    "    def __init__(self, model, max_memory=100, discount=0.95):\n",
    "        self.model = model\n",
    "        self.max_memory = max_memory\n",
    "        self.discount = discount\n",
    "        self.memory = list()\n",
    "        self.num_actions = model.output_shape[-2]\n",
    "        \n",
    "    def remember(self, epuisode):\n",
    "        self.memory.append(episode)\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "            \n",
    "    def predict(self, envstate):\n",
    "        return self.model.predict(envstate)[0]\n",
    "    \n",
    "    def get_data(self, data_size=10):\n",
    "        env_size = self.memory[0][0].shape[1]\n",
    "        mem_size = len(self.memory)\n",
    "        data_size = min(mem_size, data_size)\n",
    "        inputs = np.zeros((data_size, env_size))\n",
    "        targets = np.zeros((data_size, self.num_actions))\n",
    "        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n",
    "            envstate, action, reward, envstate_next, simulation_over = self.memory[j]\n",
    "            inputs[i] = envstate\n",
    "            targets[i] = self.predict(envstate_next)\n",
    "            Qsa = np.max(self.predict(envstate_next))\n",
    "            if simulation_over:\n",
    "                targets[i, action] = reward\n",
    "            else:\n",
    "                targets[i, action] = reward + self.discount * Qsa\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a small utility for printing readable time strings:\n",
    "def format_time(seconds):\n",
    "    if seconds < 400:\n",
    "        s = float(seconds)\n",
    "        return \"%.1f seconds\" % (s,)\n",
    "    elif seconds < 4000:\n",
    "        m = seconds / 60.0\n",
    "        return \"%.2f minutes\" % (m,)\n",
    "    else:\n",
    "        h = seconds / 3600.0\n",
    "        return \"%.2f hours\" % (h,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qtrain(model, warehouse, **hyperparameters):\n",
    "    \n",
    "    # set hyperparameters\n",
    "    global epsilon\n",
    "    n_epoch = hyperparameters.get('n_epoch', 15000)\n",
    "    max_memory = hyperparameters.get('max_memory', 1000)\n",
    "    data_size = hyperparameters.get('data_size', 50)\n",
    "    weights_file = hyperparameters.get('weights_file', \"\")\n",
    "    name = opt.get('name', 'model')\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    if weights_file:\n",
    "        print(\"loading weights from file: %s\" % (weights_file,))\n",
    "        model.load_weights(weights_file)\n",
    "        \n",
    "    # set warehouse layout\n",
    "    warehouse_state = warehouse.warehouse_state\n",
    "    SKU_data = warehouse.SKU_data\n",
    "    \n",
    "    # set experience object\n",
    "    experience = Experience(model, max_memory = max_memory)\n",
    "    \n",
    "    # simulation result log\n",
    "    simulation_log = []\n",
    "    history_size = warehouse.warehouse_layout//2\n",
    "    success_rate = 0.0\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        loss = 0.0\n",
    "        # pick any item to start placement\n",
    "        curr_SKU = random.choice(SKU_data)\n",
    "        warehouse_state.reset()   \n",
    "        n_rows = warehouse.warehouse_layout.n_rows\n",
    "        n_cols = warehouse.warehouse_layout.n_cols\n",
    "        simulation_over = False\n",
    "        \n",
    "        # observe the initial state of warehouse\n",
    "        envstate = warehouse_state.observe()\n",
    "        \n",
    "        n_episodes = 0\n",
    "        \n",
    "        while not simulation_over:\n",
    "            # create action object by passing current SKU data\n",
    "            action = Action(curr_SKU)\n",
    "        \n",
    "            prev_envstate = envstate\n",
    "            # TODO\n",
    "            # add method to warehouse_state that will generate an intermediate state with current SKU effect\n",
    "            \n",
    "            # set the placement location for current SKU either by Exploration or Exploitation\n",
    "            if np.random.rand() < epsilon:\n",
    "                action.place_location = [random.randint(0, n_rows - 1), random.randint(0, n_cols - 1)]\n",
    "            else:\n",
    "                action.place_location = experience.predict(prev_envstate) # should take the intermediate SKU effect state\n",
    "            \n",
    "            # apply action, get reward, get next warehouse state\n",
    "            envstate, reward, simulation_status = warehouse_state.act(action)\n",
    "            if simulation_status == 'success':\n",
    "                simulation_log.append(1)\n",
    "                simulation_over = True\n",
    "            elif simulation_status == 'failed':\n",
    "                simulation_log.append(0)\n",
    "                simulation_over = True\n",
    "            else:\n",
    "                simulation_over = False\n",
    "                \n",
    "            # store the experience\n",
    "            episode = [prev_envstate, action, reward, envstate, simulation_over]\n",
    "            experience.remember(episode)\n",
    "            n_episodes += 1\n",
    "            \n",
    "            # train the neural network model\n",
    "            inputs, targets = experience.get_data(data_size = data_size)\n",
    "            h = model.fit(\n",
    "                inputs,\n",
    "                targets,\n",
    "                epochs = 10,\n",
    "                batch_size = 16,\n",
    "                verbose = 0,\n",
    "            )\n",
    "            loss = model.evaluate(inputs, targets, verbose = 0)\n",
    "            \n",
    "            if len(simulation_log) > history_size:\n",
    "                success_rate = sum(simulation_log[-history_size:]) / history_size\n",
    "            \n",
    "            dt = datetime.datetime.now() - start_time\n",
    "            t = format_time(dt.total_seconds())\n",
    "            template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n",
    "            print(template.format(epoch, n_epoch-1, loss, n_episodes, sum(simulation_log), success_rate, t))\n",
    "            # we simply check if training has exhausted all free cells and if in all\n",
    "            # cases the agent won\n",
    "            if success_rate > 0.9 : epsilon = 0.05\n",
    "            if sum(simulation_log[-history_size:]) == history_size and warehouse_filled_check(model, warehouse_state):\n",
    "                print(\"Reached 100%% success rate at epoch: %d\" % (epoch,))\n",
    "                break\n",
    "            # TODO\n",
    "            # update current SKU\n",
    "            \n",
    "        # Save trained model weights and architecture\n",
    "        h5file = name + \".h5\"\n",
    "        json_file = name + \".json\"\n",
    "        model.save_weights(h5file, overwrite=True)\n",
    "        with open(json_file, \"w\") as outfile:\n",
    "            json.dump(model.to_json(), outfile)\n",
    "        end_time = datetime.datetime.now()\n",
    "        dt = datetime.datetime.now() - start_time\n",
    "        seconds = dt.total_seconds()\n",
    "        t = format_time(seconds)6        print('files: %s, %s' % (h5file, json_file))\n",
    "        print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" % (epoch, max_memory, data_size, t))\n",
    "        return seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
